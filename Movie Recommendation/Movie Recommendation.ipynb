{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project our goal is to build a movie recommendation system using collaborative filtering. Collaborative filtering is a learning technique used to make predictions (filtering) about the interests of a user by collecting preferences of taste information from many other users (collaboration). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person.\n",
    "\n",
    "For this task, the [Movielens dataset](https://grouplens.org/datasets/movielens/) was used. It contains 20 million ratings and 465000 tag applications applied to 27000 movies by 138000 users.\n",
    "\n",
    "The Apache Spark framework (and its Machine Learning library) was used to process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some functionalities of the Spark SQL component will be used, we need to initialize a `SparkSession` object.\n",
    "\n",
    "The `SparkContext` object (required for other basic functionalities) is automatically created by PySpark and it is defined in the `sc` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.appName(\"Movie Recommendation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens dataset is composed of three text files:\n",
    "\n",
    "- `users.dat`: contains information about the genre, age, occupation and zipcode of each user.\n",
    "- `movies.dat`: contains information about the title, year and genres of each movie.\n",
    "- `ratings.dat`: contains the ratings that users gave to the movies they watched.\n",
    "\n",
    "They can be opened as plain text RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::F::1::10::48067',\n",
       " '2::M::56::16::70072',\n",
       " '3::M::25::15::55117',\n",
       " '4::M::45::7::02460',\n",
       " '5::M::25::20::55455']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersRdd0 = sc.textFile(os.path.join(\"ml-1m\", \"users.dat\"))\n",
    "usersRdd0.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1::Toy Story (1995)::Animation|Children's|Comedy\",\n",
       " \"2::Jumanji (1995)::Adventure|Children's|Fantasy\",\n",
       " '3::Grumpier Old Men (1995)::Comedy|Romance',\n",
       " '4::Waiting to Exhale (1995)::Comedy|Drama',\n",
       " '5::Father of the Bride Part II (1995)::Comedy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRdd0 = sc.textFile(os.path.join(\"ml-1m\", \"movies.dat\"))\n",
    "moviesRdd0.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::1193::5::978300760',\n",
       " '1::661::3::978302109',\n",
       " '1::914::3::978301968',\n",
       " '1::3408::4::978300275',\n",
       " '1::2355::5::978824291']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsRdd0 = sc.textFile(os.path.join(\"ml-1m\", \"ratings.dat\"))\n",
    "ratingsRdd0.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plain text RDDs must be converted to structured data so we can use SQL queries and other high level operations to manipulate them. This is done for each RDD separately as each dataset has its own schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import Row\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the MovieLens dataset's documentation, each user record is composed of 5 fields:\n",
    "\n",
    "- userID: User's unique identification.\n",
    "- gender: User's gender (\"F\" for females, \"M\" for males).\n",
    "- age: User's age range encoded as a number (see below).\n",
    "- occupation: User's occupation encoded as a number (see below).\n",
    "- zipcode: User's zipcode.\n",
    "\n",
    "We usually need to encode categorical features as numbers (or sets of binary features) in order to use them in predictive models. Here, the `age` and `occupation` field values are already encoded; however, in a preliminary analysis it might be useful to know their actual values for the sake of interpretation. So this default encoding is undone and the codes are translated to the actual values they represent. Later, when needed, we may encode them again using Spark's `StringIndexer` class.\n",
    "\n",
    "Thus, in the following cells the plain textual data for each user is split, the field values are computed, and the result is put into a structured `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agesDict = {\n",
    "    \"1\": \"Under 18\",\n",
    "    \"18\": \"18-24\",\n",
    "    \"25\": \"25-34\",\n",
    "    \"35\": \"35-44\",\n",
    "    \"45\": \"45-49\",\n",
    "    \"50\": \"50-55\",\n",
    "    \"56\": \"Over 56\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occupationsDict = {\n",
    "    \"0\": \"other or unspecified\",\n",
    "    \"1\": \"academic/educator\",\n",
    "    \"2\": \"artist\",\n",
    "    \"3\": \"clerical/admin\",\n",
    "    \"4\": \"college/grad student\",\n",
    "    \"5\": \"customer service\",\n",
    "    \"6\": \"doctor/health care\",\n",
    "    \"7\": \"executive/managerial\",\n",
    "    \"8\": \"farmer\",\n",
    "    \"9\": \"homemaker\",\n",
    "    \"10\": \"K-12 student\",\n",
    "    \"11\": \"lawyer\",\n",
    "    \"12\": \"programmer\",\n",
    "    \"13\": \"retired\",\n",
    "    \"14\": \"sales/marketing\",\n",
    "    \"15\": \"scientist\",\n",
    "    \"16\": \"self-employed\",\n",
    "    \"17\": \"technician/engineer\",\n",
    "    \"18\": \"tradesman/craftsman\",\n",
    "    \"19\": \"unemployed\",\n",
    "    \"20\": \"writer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age='Under 18', gender='F', occupation='K-12 student', userID=1, zipcode='48067'),\n",
       " Row(age='Over 56', gender='M', occupation='self-employed', userID=2, zipcode='70072'),\n",
       " Row(age='25-34', gender='M', occupation='scientist', userID=3, zipcode='55117'),\n",
       " Row(age='45-49', gender='M', occupation='executive/managerial', userID=4, zipcode='02460'),\n",
       " Row(age='25-34', gender='M', occupation='writer', userID=5, zipcode='55455')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersRdd1 = usersRdd0.map(lambda line: line.split(\"::\")) \\\n",
    "                     .map(lambda t: Row(userID=int(t[0]),\n",
    "                                        gender=t[1],\n",
    "                                        age=agesDict[t[2]],\n",
    "                                        occupation=occupationsDict[t[3]],\n",
    "                                        zipcode=t[4]))\n",
    "usersRdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[10] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersRdd1.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+-------+\n",
      "|age     |gender|occupation          |userID|zipcode|\n",
      "+--------+------+--------------------+------+-------+\n",
      "|Under 18|F     |K-12 student        |1     |48067  |\n",
      "|Over 56 |M     |self-employed       |2     |70072  |\n",
      "|25-34   |M     |scientist           |3     |55117  |\n",
      "|45-49   |M     |executive/managerial|4     |02460  |\n",
      "|25-34   |M     |writer              |5     |55455  |\n",
      "+--------+------+--------------------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersDf1 = ss.createDataFrame(usersRdd1)\n",
    "usersDf1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: string, gender: string, occupation: string, userID: bigint, zipcode: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersDf1.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, each movie record is composed of 3 fields:\n",
    "\n",
    "- movieID: Movie's unique identification.\n",
    "- title: Movie's title and year (see below).\n",
    "- genres: List of all genres the movie fits to.\n",
    "\n",
    "The `title` field includes the movie's year because there are movies with same name made (or remade) in different epochs, and the year information would be the only way to distinct them. However, as we have a `movieID` field, this is not really necessary. So we can extract the year from the title and make another field.\n",
    "\n",
    "Thus, in the following cells the plain textual data for each movie is split, the field values are computed, and the result is put into a structured `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(genres=['Animation', \"Children's\", 'Comedy'], movieID=1, title='Toy Story', year=1995),\n",
       " Row(genres=['Adventure', \"Children's\", 'Fantasy'], movieID=2, title='Jumanji', year=1995),\n",
       " Row(genres=['Comedy', 'Romance'], movieID=3, title='Grumpier Old Men', year=1995),\n",
       " Row(genres=['Comedy', 'Drama'], movieID=4, title='Waiting to Exhale', year=1995),\n",
       " Row(genres=['Comedy'], movieID=5, title='Father of the Bride Part II', year=1995)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRdd1 = moviesRdd0.map(lambda line: line.split(\"::\")) \\\n",
    "                       .map(lambda t: Row(movieID=int(t[0]),\n",
    "                                          title=t[1][:-7],\n",
    "                                          year=int(t[1][-5:-1]),\n",
    "                                          genres=t[2].split(\"|\")))\n",
    "moviesRdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[21] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRdd1.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------+---------------------------+----+\n",
      "|genres                          |movieID|title                      |year|\n",
      "+--------------------------------+-------+---------------------------+----+\n",
      "|[Animation, Children's, Comedy] |1      |Toy Story                  |1995|\n",
      "|[Adventure, Children's, Fantasy]|2      |Jumanji                    |1995|\n",
      "|[Comedy, Romance]               |3      |Grumpier Old Men           |1995|\n",
      "|[Comedy, Drama]                 |4      |Waiting to Exhale          |1995|\n",
      "|[Comedy]                        |5      |Father of the Bride Part II|1995|\n",
      "+--------------------------------+-------+---------------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDf1 = ss.createDataFrame(moviesRdd1)\n",
    "moviesDf1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[genres: array<string>, movieID: bigint, title: string, year: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDf1.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each rating data is composed of 4 fields:\n",
    "\n",
    "- userID: ID of the user who gave the rating.\n",
    "- movieID: ID of the movie which was rated.\n",
    "- rating: A numerical value ranging from 1 (min) to 5 (max).\n",
    "- timestamp: A number that encodes the date and time the rating was given at.\n",
    "\n",
    "The `timestamp` can be easily converted to a `datetime` object, which is much easier to interpret.\n",
    "\n",
    "Thus, in the following cells the plain textual data for each rating is split, the field values are computed, and the result is put into a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieID=1193, rating=5.0, timestamp=datetime.datetime(2000, 12, 31, 20, 12, 40), userID=1),\n",
       " Row(movieID=661, rating=3.0, timestamp=datetime.datetime(2000, 12, 31, 20, 35, 9), userID=1),\n",
       " Row(movieID=914, rating=3.0, timestamp=datetime.datetime(2000, 12, 31, 20, 32, 48), userID=1),\n",
       " Row(movieID=3408, rating=4.0, timestamp=datetime.datetime(2000, 12, 31, 20, 4, 35), userID=1),\n",
       " Row(movieID=2355, rating=5.0, timestamp=datetime.datetime(2001, 1, 6, 21, 38, 11), userID=1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsRdd1 = ratingsRdd0.map(lambda line: line.split(\"::\")) \\\n",
    "                         .map(lambda t: Row(userID=int(t[0]),\n",
    "                                            movieID=int(t[1]),\n",
    "                                            rating=float(t[2]),\n",
    "                                            timestamp=dt.datetime.fromtimestamp(int(t[3]))))\n",
    "ratingsRdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[32] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsRdd1.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------------------+------+\n",
      "|movieID|rating|timestamp            |userID|\n",
      "+-------+------+---------------------+------+\n",
      "|1193   |5.0   |2000-12-31 20:12:40.0|1     |\n",
      "|661    |3.0   |2000-12-31 20:35:09.0|1     |\n",
      "|914    |3.0   |2000-12-31 20:32:48.0|1     |\n",
      "|3408   |4.0   |2000-12-31 20:04:35.0|1     |\n",
      "|2355   |5.0   |2001-01-06 21:38:11.0|1     |\n",
      "+-------+------+---------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingsDf1 = ss.createDataFrame(ratingsRdd1)\n",
    "ratingsDf1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, rating: double, timestamp: timestamp, userID: bigint]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsDf1.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll just do some exploration on the structured datasets in order to better understand all the data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usersDf1.createOrReplaceTempView(\"users\")\n",
    "moviesDf1.createOrReplaceTempView(\"movies\")\n",
    "ratingsDf1.createOrReplaceTempView(\"ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|gender|frequency|\n",
      "+------+---------+\n",
      "|     M|     4331|\n",
      "|     F|     1709|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the gender distribution.\n",
    "ss.sql(\"\"\"SELECT gender, \n",
    "                 COUNT(gender) as frequency\n",
    "          FROM users\n",
    "          GROUP BY gender\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|     age|frequency|\n",
      "+--------+---------+\n",
      "|   25-34|     2096|\n",
      "|   35-44|     1193|\n",
      "|   18-24|     1103|\n",
      "|   45-49|      550|\n",
      "|   50-55|      496|\n",
      "| Over 56|      380|\n",
      "|Under 18|      222|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the age distribution.\n",
    "ss.sql(\"\"\"SELECT age,\n",
    "                 COUNT(age) as frequency\n",
    "          FROM users\n",
    "          GROUP BY age\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|          occupation|frequency|\n",
      "+--------------------+---------+\n",
      "|college/grad student|      759|\n",
      "|other or unspecified|      711|\n",
      "|executive/managerial|      679|\n",
      "|   academic/educator|      528|\n",
      "| technician/engineer|      502|\n",
      "|          programmer|      388|\n",
      "|     sales/marketing|      302|\n",
      "|              writer|      281|\n",
      "|              artist|      267|\n",
      "|       self-employed|      241|\n",
      "|  doctor/health care|      236|\n",
      "|        K-12 student|      195|\n",
      "|      clerical/admin|      173|\n",
      "|           scientist|      144|\n",
      "|             retired|      142|\n",
      "|              lawyer|      129|\n",
      "|    customer service|      112|\n",
      "|           homemaker|       92|\n",
      "|          unemployed|       72|\n",
      "| tradesman/craftsman|       70|\n",
      "|              farmer|       17|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the occupation distribution.\n",
    "ss.sql(\"\"\"SELECT occupation,\n",
    "                 COUNT(occupation) as frequency\n",
    "          FROM users\n",
    "          GROUP BY occupation\n",
    "          ORDER BY frequency DESC\"\"\").show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+---------+\n",
      "|gender|     age|          occupation|frequency|\n",
      "+------+--------+--------------------+---------+\n",
      "|     M|   18-24|college/grad student|      371|\n",
      "|     M|   25-34|other or unspecified|      206|\n",
      "|     M|   25-34|executive/managerial|      191|\n",
      "|     M|   25-34| technician/engineer|      180|\n",
      "|     M|   35-44|executive/managerial|      177|\n",
      "|     M|   25-34|          programmer|      164|\n",
      "|     F|   18-24|college/grad student|      163|\n",
      "|     M|   25-34|college/grad student|      141|\n",
      "|     M|   35-44| technician/engineer|      116|\n",
      "|     M|Under 18|        K-12 student|      100|\n",
      "|     M|   25-34|     sales/marketing|       97|\n",
      "|     F|   25-34|other or unspecified|       92|\n",
      "|     M|   35-44|other or unspecified|       92|\n",
      "|     M|   25-34|              writer|       89|\n",
      "|     M|   25-34|   academic/educator|       87|\n",
      "|     M|   25-34|              artist|       82|\n",
      "|     M|   35-44|   academic/educator|       77|\n",
      "|     M| Over 56|             retired|       75|\n",
      "|     M|   18-24|other or unspecified|       74|\n",
      "|     M|   35-44|          programmer|       71|\n",
      "+------+--------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the user groups stratified.\n",
    "ss.sql(\"\"\"SELECT gender,\n",
    "                 age,\n",
    "                 occupation,\n",
    "                 COUNT(*) as frequency\n",
    "          FROM users\n",
    "          GROUP BY gender, age, occupation\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So most of our users belong to the group of male college/grad students aged 18-24, which was kinda expected. The next 3 most populated groups are also composed of men, with various occupations and aged 25-34. Oddly, female users are a minority (why did women watch/rate about 3 times less movies than men? This is probably worthy a deeper investigation...), as well as people at the limits of the age distribution (under 18 and above 56). Not surprisingly, farmers and tradesman/craftsman are among the least frequent user occupations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|year|frequency|\n",
      "+----+---------+\n",
      "|1996|      345|\n",
      "|1995|      342|\n",
      "|1998|      337|\n",
      "|1997|      315|\n",
      "|1999|      283|\n",
      "|1994|      257|\n",
      "|1993|      165|\n",
      "|2000|      156|\n",
      "|1986|      104|\n",
      "|1992|      102|\n",
      "|1990|       77|\n",
      "|1987|       71|\n",
      "|1988|       69|\n",
      "|1985|       65|\n",
      "|1989|       60|\n",
      "|1984|       60|\n",
      "|1991|       60|\n",
      "|1982|       50|\n",
      "|1981|       43|\n",
      "|1980|       41|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the year distribution.\n",
    "ss.sql(\"\"\"SELECT year,\n",
    "                 COUNT(year) as frequency\n",
    "          FROM movies\n",
    "          GROUP BY year\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+\n",
      "|min_year|max_year|avg_year|\n",
      "+--------+--------+--------+\n",
      "|    1919|    2000|  1986.1|\n",
      "+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get some year statistics.\n",
    "ss.sql(\"\"\"SELECT MIN(year) as min_year,\n",
    "                 MAX(year) as max_year,\n",
    "                 ROUND(AVG(year), 1) as avg_year\n",
    "          FROM movies\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the movies in our dataset were made between the years of 1919 and 2000. Most of them are from more recent decades, since the mean year is 1986. More precisely, most rated movies are from the 1990s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|rating|frequency|\n",
      "+------+---------+\n",
      "|   4.0|   348971|\n",
      "|   3.0|   261197|\n",
      "|   5.0|   226310|\n",
      "|   2.0|   107557|\n",
      "|   1.0|    56174|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the rating distribution.\n",
    "ss.sql(\"\"\"SELECT rating,\n",
    "                 COUNT(rating) as frequency\n",
    "          FROM ratings\n",
    "          GROUP BY rating\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+\n",
      "|userID|numRatings|avgRating|\n",
      "+------+----------+---------+\n",
      "|  4169|      2314|      3.6|\n",
      "|  1680|      1850|      3.6|\n",
      "|  4277|      1743|      4.1|\n",
      "|  1941|      1595|      3.1|\n",
      "|  1181|      1521|      2.8|\n",
      "|   889|      1518|      2.8|\n",
      "|  3618|      1344|      3.0|\n",
      "|  2063|      1323|      2.9|\n",
      "|  1150|      1302|      2.6|\n",
      "|  1015|      1286|      3.7|\n",
      "|  5795|      1277|      3.1|\n",
      "|  4344|      1271|      3.3|\n",
      "|  1980|      1260|      3.5|\n",
      "|  2909|      1258|      3.8|\n",
      "|  1449|      1243|      2.8|\n",
      "|  4510|      1240|      2.8|\n",
      "|   424|      1226|      3.7|\n",
      "|  4227|      1222|      2.7|\n",
      "|  5831|      1220|      3.7|\n",
      "|  3841|      1216|      3.3|\n",
      "+------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the most active users and their average ratings.\n",
    "ss.sql(\"\"\"SELECT userID,\n",
    "                 COUNT(userID) as numRatings,\n",
    "                 ROUND(AVG(rating), 1) as avgRating\n",
    "          FROM ratings\n",
    "          GROUP BY userID\n",
    "          ORDER BY numRatings DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+----+----------+---------+\n",
      "|title                                         |year|numRatings|avgRating|\n",
      "+----------------------------------------------+----+----------+---------+\n",
      "|American Beauty                               |1999|3428      |4.3      |\n",
      "|Star Wars: Episode IV - A New Hope            |1977|2991      |4.5      |\n",
      "|Star Wars: Episode V - The Empire Strikes Back|1980|2990      |4.3      |\n",
      "|Star Wars: Episode VI - Return of the Jedi    |1983|2883      |4.0      |\n",
      "|Jurassic Park                                 |1993|2672      |3.8      |\n",
      "|Saving Private Ryan                           |1998|2653      |4.3      |\n",
      "|Terminator 2: Judgment Day                    |1991|2649      |4.1      |\n",
      "|Matrix, The                                   |1999|2590      |4.3      |\n",
      "|Back to the Future                            |1985|2583      |4.0      |\n",
      "|Silence of the Lambs, The                     |1991|2578      |4.4      |\n",
      "|Men in Black                                  |1997|2538      |3.7      |\n",
      "|Raiders of the Lost Ark                       |1981|2514      |4.5      |\n",
      "|Fargo                                         |1996|2513      |4.3      |\n",
      "|Sixth Sense, The                              |1999|2459      |4.4      |\n",
      "|Braveheart                                    |1995|2443      |4.2      |\n",
      "|Shakespeare in Love                           |1998|2369      |4.1      |\n",
      "|Princess Bride, The                           |1987|2318      |4.3      |\n",
      "|Schindler's List                              |1993|2304      |4.5      |\n",
      "|L.A. Confidential                             |1997|2288      |4.2      |\n",
      "|Groundhog Day                                 |1993|2278      |4.0      |\n",
      "+----------------------------------------------+----+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the most rated movies and their average ratings.\n",
    "ss.sql(\"\"\"SELECT movies.title,\n",
    "                 movies.year,\n",
    "                 COUNT(ratings.movieID) as numRatings,\n",
    "                 ROUND(AVG(ratings.rating), 1) as avgRating\n",
    "          FROM ratings\n",
    "          INNER JOIN movies\n",
    "          ON ratings.movieID = movies.movieID\n",
    "          GROUP BY ratings.movieID,\n",
    "                   movies.title,\n",
    "                   movies.year\n",
    "          ORDER BY numRatings DESC\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 4 stars is the most common rating and 1-2 stars are the least ones, we can say that there aren't many terribly bad movies in the dataset (in our users' oppinions). There are users that rated over 1000 movies (they probably should be rewarded for their contribution!), as well as movies that were rated by over 2000 users. American Beauty (1999) was the most rated movie, followed by the classic Star Wars trilogy (episodes IV-VI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss.catalog.dropTempView(\"users\")\n",
    "ss.catalog.dropTempView(\"movies\")\n",
    "ss.catalog.dropTempView(\"ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing stage aims to put users' and movies' data in good shape for the learning algorithms that come later. This involves feature encoding, scaling, joining, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.pipeline import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol\n",
    "from pyspark.ml.param.shared import HasOutputCol\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source: http://stackoverflow.com/questions/41259885/sparsevector-vs-densevector-when-using-standardscaler\n",
    "class AsDenseTransformer(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(AsDenseTransformer, self).__init__()\n",
    "        kwargs = self.__init__._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None):\n",
    "        kwargs = self.setParams._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        \n",
    "        asDense = udf(lambda s: DenseVector(s.toArray()), VectorUDT())\n",
    "        \n",
    "        return dataset.withColumn(out_col,  asDense(in_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gender` and `age` fields can be simply encoded as numbers, since `gender` has only 2 possible values (`\"M\" -> 0`, `\"F\" -> 1`) and `age` is actually an ordinal variable (i.e. there is an implicit ordering of its categories). For the `occupation` field, we use one-hot encoding to convert it to a sequence of binary features. All features are joined together in a single feature vector and then scaled to zero mean and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genderIndexer = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\")\n",
    "ageIndexer = StringIndexer(inputCol=\"age\", outputCol=\"ageIndex\")\n",
    "occupationIndexer = StringIndexer(inputCol=\"occupation\", outputCol=\"occupationIndex\")\n",
    "occupationEncoder = OneHotEncoder(inputCol=\"occupationIndex\", outputCol=\"occupationVector\")\n",
    "usersAssembler = VectorAssembler(inputCols=[\"genderIndex\", \"ageIndex\", \"occupationVector\"],\n",
    "                                 outputCol=\"sparseFeatures\")\n",
    "usersAsDenseTransform = AsDenseTransformer(inputCol=\"sparseFeatures\", outputCol=\"denseFeatures\")\n",
    "usersScaler = StandardScaler(inputCol=\"denseFeatures\", outputCol=\"scaledFeatures\",\n",
    "                             withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usersPipeline = Pipeline(stages=[genderIndexer,\n",
    "                                 ageIndexer,\n",
    "                                 occupationIndexer,\n",
    "                                 occupationEncoder,\n",
    "                                 usersAssembler,\n",
    "                                 usersAsDenseTransform,\n",
    "                                 usersScaler])\n",
    "usersTransformer = usersPipeline.fit(usersDf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userID|      scaledFeatures|\n",
      "+------+--------------------+\n",
      "|     1|[1.59179488929462...|\n",
      "|     2|[-0.6281176323723...|\n",
      "|     3|[-0.6281176323723...|\n",
      "|     4|[-0.6281176323723...|\n",
      "|     5|[-0.6281176323723...|\n",
      "|     6|[1.59179488929462...|\n",
      "|     7|[-0.6281176323723...|\n",
      "|     8|[-0.6281176323723...|\n",
      "|     9|[-0.6281176323723...|\n",
      "|    10|[1.59179488929462...|\n",
      "|    11|[1.59179488929462...|\n",
      "|    12|[-0.6281176323723...|\n",
      "|    13|[-0.6281176323723...|\n",
      "|    14|[-0.6281176323723...|\n",
      "|    15|[-0.6281176323723...|\n",
      "|    16|[1.59179488929462...|\n",
      "|    17|[-0.6281176323723...|\n",
      "|    18|[1.59179488929462...|\n",
      "|    19|[-0.6281176323723...|\n",
      "|    20|[-0.6281176323723...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersDf2 = usersTransformer.transform(usersDf1)\n",
    "usersDf2.select(\"userID\", \"scaledFeatures\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: string, gender: string, occupation: string, userID: bigint, zipcode: string, genderIndex: double, ageIndex: double, occupationIndex: double, occupationVector: vector, sparseFeatures: vector, denseFeatures: vector, scaledFeatures: vector]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersDf2.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: string, gender: string, occupation: string, userID: bigint, zipcode: string]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersRdd1.unpersist()\n",
    "usersDf1.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `genre` list information is mapped to a set of 18 new binary features, where each one tells whether that movie belongs to some genre or not. These features are then joined to the `year` information in a single feature vector, which is then scaled to zero mean and unit standard deviation. The `title` is not useful in terms of describing the characteristics of a movie (since it is basically a unique identifier), therefore it is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(genreAction=0, genreAdventure=0, genreAnimation=1, genreChildrens=1, genreComedy=1, genreCrime=0, genreDocumentary=0, genreDrama=0, genreFantasy=0, genreFilmNoir=0, genreHorror=0, genreMusical=0, genreMystery=0, genreRomance=0, genreSciFi=0, genreThriller=0, genreWar=0, genreWestern=0, movieID=1),\n",
       " Row(genreAction=0, genreAdventure=1, genreAnimation=0, genreChildrens=1, genreComedy=0, genreCrime=0, genreDocumentary=0, genreDrama=0, genreFantasy=1, genreFilmNoir=0, genreHorror=0, genreMusical=0, genreMystery=0, genreRomance=0, genreSciFi=0, genreThriller=0, genreWar=0, genreWestern=0, movieID=2),\n",
       " Row(genreAction=0, genreAdventure=0, genreAnimation=0, genreChildrens=0, genreComedy=1, genreCrime=0, genreDocumentary=0, genreDrama=0, genreFantasy=0, genreFilmNoir=0, genreHorror=0, genreMusical=0, genreMystery=0, genreRomance=1, genreSciFi=0, genreThriller=0, genreWar=0, genreWestern=0, movieID=3),\n",
       " Row(genreAction=0, genreAdventure=0, genreAnimation=0, genreChildrens=0, genreComedy=1, genreCrime=0, genreDocumentary=0, genreDrama=1, genreFantasy=0, genreFilmNoir=0, genreHorror=0, genreMusical=0, genreMystery=0, genreRomance=0, genreSciFi=0, genreThriller=0, genreWar=0, genreWestern=0, movieID=4),\n",
       " Row(genreAction=0, genreAdventure=0, genreAnimation=0, genreChildrens=0, genreComedy=1, genreCrime=0, genreDocumentary=0, genreDrama=0, genreFantasy=0, genreFilmNoir=0, genreHorror=0, genreMusical=0, genreMystery=0, genreRomance=0, genreSciFi=0, genreThriller=0, genreWar=0, genreWestern=0, movieID=5)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genresRdd = moviesRdd1.map(lambda row: Row(movieID=row.movieID,\n",
    "                                           genreAction=int(\"Action\" in row.genres),\n",
    "                                           genreAdventure=int(\"Adventure\" in row.genres),\n",
    "                                           genreAnimation=int(\"Animation\" in row.genres),\n",
    "                                           genreChildrens=int(\"Children's\" in row.genres),\n",
    "                                           genreComedy=int(\"Comedy\" in row.genres),\n",
    "                                           genreCrime=int(\"Crime\" in row.genres),\n",
    "                                           genreDocumentary=int(\"Documentary\" in row.genres),\n",
    "                                           genreDrama=int(\"Drama\" in row.genres),\n",
    "                                           genreFantasy=int(\"Fantasy\" in row.genres),\n",
    "                                           genreFilmNoir=int(\"Film-Noir\" in row.genres),\n",
    "                                           genreHorror=int(\"Horror\" in row.genres),\n",
    "                                           genreMusical=int(\"Musical\" in row.genres),\n",
    "                                           genreMystery=int(\"Mystery\" in row.genres),\n",
    "                                           genreRomance=int(\"Romance\" in row.genres),\n",
    "                                           genreSciFi=int(\"Sci-Fi\" in row.genres),\n",
    "                                           genreThriller=int(\"Thriller\" in row.genres),\n",
    "                                           genreWar=int(\"War\" in row.genres),\n",
    "                                           genreWestern=int(\"Western\" in row.genres)))\n",
    "genresRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genresDf = ss.createDataFrame(genresRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieID: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- genreAction: long (nullable = true)\n",
      " |-- genreAdventure: long (nullable = true)\n",
      " |-- genreAnimation: long (nullable = true)\n",
      " |-- genreChildrens: long (nullable = true)\n",
      " |-- genreComedy: long (nullable = true)\n",
      " |-- genreCrime: long (nullable = true)\n",
      " |-- genreDocumentary: long (nullable = true)\n",
      " |-- genreDrama: long (nullable = true)\n",
      " |-- genreFantasy: long (nullable = true)\n",
      " |-- genreFilmNoir: long (nullable = true)\n",
      " |-- genreHorror: long (nullable = true)\n",
      " |-- genreMusical: long (nullable = true)\n",
      " |-- genreMystery: long (nullable = true)\n",
      " |-- genreRomance: long (nullable = true)\n",
      " |-- genreSciFi: long (nullable = true)\n",
      " |-- genreThriller: long (nullable = true)\n",
      " |-- genreWar: long (nullable = true)\n",
      " |-- genreWestern: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDf2 = moviesDf1.join(genresDf, [\"movieID\"]).drop(\"genres\")\n",
    "moviesDf2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviesAssembler = VectorAssembler(inputCols=[\"year\"] + [x for x in moviesDf2.schema.names if \"genre\" in x],\n",
    "                                  outputCol=\"sparseFeatures\")\n",
    "moviesAsDenseTransform = AsDenseTransformer(inputCol=\"sparseFeatures\", outputCol=\"denseFeatures\")\n",
    "moviesScaler = StandardScaler(inputCol=\"denseFeatures\", outputCol=\"scaledFeatures\",\n",
    "                              withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviesPipeline = Pipeline(stages=[moviesAssembler,\n",
    "                                  moviesAsDenseTransform,\n",
    "                                  moviesScaler])\n",
    "moviesTransformer = moviesPipeline.fit(moviesDf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieID|      scaledFeatures|\n",
      "+-------+--------------------+\n",
      "|     26|[0.52871716866845...|\n",
      "|     29|[0.52871716866845...|\n",
      "|    474|[0.41034378579074...|\n",
      "|    964|[-2.3122440203966...|\n",
      "|   1677|[0.64709055154616...|\n",
      "|   1697|[0.46953047722959...|\n",
      "|   1806|[0.70627724298502...|\n",
      "|   1950|[-1.1285101916195...|\n",
      "|   2040|[-0.9509501173029...|\n",
      "|   2214|[-3.2000443919795...|\n",
      "|   2250|[0.23278371147416...|\n",
      "|   2453|[-0.0039630542812...|\n",
      "|   2509|[0.64709055154616...|\n",
      "|   2529|[-1.0693235001806...|\n",
      "|   2927|[-2.3714307118355...|\n",
      "|   3091|[-0.3590832029144...|\n",
      "|   3506|[-0.4182698943532...|\n",
      "|   3764|[0.35115709435188...|\n",
      "|     65|[0.58790386010731...|\n",
      "|    191|[0.52871716866845...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDf3 = moviesTransformer.transform(moviesDf2)\n",
    "moviesDf3.select(\"movieID\", \"scaledFeatures\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, title: string, year: bigint, genreAction: bigint, genreAdventure: bigint, genreAnimation: bigint, genreChildrens: bigint, genreComedy: bigint, genreCrime: bigint, genreDocumentary: bigint, genreDrama: bigint, genreFantasy: bigint, genreFilmNoir: bigint, genreHorror: bigint, genreMusical: bigint, genreMystery: bigint, genreRomance: bigint, genreSciFi: bigint, genreThriller: bigint, genreWar: bigint, genreWestern: bigint, sparseFeatures: vector, denseFeatures: vector, scaledFeatures: vector]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDf3.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[genres: array<string>, movieID: bigint, title: string, year: bigint]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRdd1.unpersist()\n",
    "moviesDf1.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to do when we have to recommend movies to a new user that never rated anything before (i.e. we know nothing about his/her tastes)? A common approach is to just recommend the overall top rated movies. This can be done in a simple manner by computing the rates relative to their respective averages and then, in the end, adding the average rate to each movie's predicted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|movieID|       avg(rating)|\n",
      "+-------+------------------+\n",
      "|     29| 4.062034739454094|\n",
      "|   1806| 2.892857142857143|\n",
      "|    474| 3.825102880658436|\n",
      "|   2453|              3.25|\n",
      "|   2529| 3.712564543889845|\n",
      "|   2040|         2.9453125|\n",
      "|     26|              3.53|\n",
      "|   3506|3.3652694610778444|\n",
      "|   3091| 4.283687943262412|\n",
      "|   2250|3.1451612903225805|\n",
      "|   1677|2.7567567567567566|\n",
      "|   1950| 4.129310344827586|\n",
      "|   3764|2.6408163265306124|\n",
      "|   2927|  4.08080808080808|\n",
      "|    964| 3.392156862745098|\n",
      "|   2509|2.7777777777777777|\n",
      "|   2214|               3.0|\n",
      "|   1840|           3.38125|\n",
      "|   1277| 3.884297520661157|\n",
      "|    541| 4.273333333333333|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avgRatingsDf = ratingsDf1.groupBy(\"movieID\").avg(\"rating\")\n",
    "avgRatingsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, avg(rating): double]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgRatingsDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratingsDf2 = ratingsDf1.join(avgRatingsDf, [\"movieID\"]) \\\n",
    "                       .select(\"*\", col(\"rating\") - col(\"avg(rating)\")) \\\n",
    "                       .withColumnRenamed(\"(rating - avg(rating))\", \"adjustedRating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userID|movieID|rating|     adjustedRating|\n",
      "+------+-------+------+-------------------+\n",
      "|    18|     26|   4.0| 0.4700000000000002|\n",
      "|    69|     26|   4.0| 0.4700000000000002|\n",
      "|   229|     26|   4.0| 0.4700000000000002|\n",
      "|   342|     26|   4.0| 0.4700000000000002|\n",
      "|   524|     26|   3.0|-0.5299999999999998|\n",
      "|   655|     26|   3.0|-0.5299999999999998|\n",
      "|   748|     26|   5.0| 1.4700000000000002|\n",
      "|   881|     26|   3.0|-0.5299999999999998|\n",
      "|   890|     26|   3.0|-0.5299999999999998|\n",
      "|   918|     26|   4.0| 0.4700000000000002|\n",
      "|   963|     26|   4.0| 0.4700000000000002|\n",
      "|   973|     26|   4.0| 0.4700000000000002|\n",
      "|  1015|     26|   3.0|-0.5299999999999998|\n",
      "|  1069|     26|   3.0|-0.5299999999999998|\n",
      "|  1120|     26|   3.0|-0.5299999999999998|\n",
      "|  1150|     26|   3.0|-0.5299999999999998|\n",
      "|  1182|     26|   2.0|-1.5299999999999998|\n",
      "|  1203|     26|   4.0| 0.4700000000000002|\n",
      "|  1279|     26|   3.0|-0.5299999999999998|\n",
      "|  1314|     26|   1.0|              -2.53|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingsDf2.select(\"userID\", \"movieID\", \"rating\", \"adjustedRating\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, rating: double, timestamp: timestamp, userID: bigint, avg(rating): double, adjustedRating: double]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsDf2.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, rating: double, timestamp: timestamp, userID: bigint]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsRdd1.unpersist()\n",
    "ratingsDf1.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, three types of models are going to be trained: \n",
    "\n",
    "* The collaborative filtering model, which is the main engine we use for the recommendations;\n",
    "* Two secondary, content-based models: one that learns to predict scores based on movie features for each user, and other that learns to predict scores based on user features for each movie.\n",
    "\n",
    "The goal is to use one of the secondary models as a substitute for the collaborative filtering when the movie has no rating at all, because in such situation the collaborative filtering doesn't have enough information to predict anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering (Alternating Least Squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collaborative filtering technique only requires us to provide the user IDs, the movie IDs and the rating each user gave to each movie they watched.\n",
    "\n",
    "Model tuning (finding the best combination of model parameters) was performed using a grid-search with a 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alternating Least Squares (ALS) estimator.\n",
    "als = ALS(userCol=\"userID\",\n",
    "          itemCol=\"movieID\",\n",
    "          ratingCol=\"adjustedRating\",\n",
    "          maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the parameter grid for tuning.\n",
    "alsParamGrid = ParamGridBuilder().addGrid(als.regParam, [0.001, 0.01, 0.1, 1, 10]) \\\n",
    "                                 .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3-fold cross-validation.\n",
    "alsCV = CrossValidator(estimator=als,\n",
    "                       estimatorParamMaps=alsParamGrid,\n",
    "                       evaluator=RegressionEvaluator(labelCol=\"adjustedRating\"),\n",
    "                       numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alsModel = alsCV.fit(ratingsDf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+-----------+\n",
      "|userID|movieID|rating|     adjustedRating| prediction|\n",
      "+------+-------+------+-------------------+-----------+\n",
      "|    53|    148|   5.0|  2.217391304347826|    1.88291|\n",
      "|   673|    148|   5.0|  2.217391304347826|  2.2567441|\n",
      "|  4169|    148|   3.0|0.21739130434782616| 0.72547275|\n",
      "|  4227|    148|   2.0|-0.7826086956521738| -1.0292696|\n",
      "|  5333|    148|   3.0|0.21739130434782616| -0.7330352|\n",
      "|  3184|    148|   4.0| 1.2173913043478262|  1.2678249|\n",
      "|  4387|    148|   1.0|-1.7826086956521738| -1.4056144|\n",
      "|  4784|    148|   3.0|0.21739130434782616|  1.0220977|\n",
      "|  2383|    148|   2.0|-0.7826086956521738| -0.6611125|\n",
      "|  1242|    148|   3.0|0.21739130434782616|-0.18989654|\n",
      "|  3539|    148|   3.0|0.21739130434782616| 0.11645946|\n",
      "|  1069|    148|   2.0|-0.7826086956521738| -0.8080865|\n",
      "|  1605|    148|   2.0|-0.7826086956521738|-0.93036544|\n",
      "|   840|    148|   1.0|-1.7826086956521738| -0.8153674|\n",
      "|   216|    148|   2.0|-0.7826086956521738|-0.24676943|\n",
      "|   482|    148|   2.0|-0.7826086956521738| 0.15567838|\n",
      "|   752|    148|   4.0| 1.2173913043478262| 0.35111743|\n",
      "|  1150|    148|   2.0|-0.7826086956521738| -0.1504606|\n",
      "|  3829|    148|   2.0|-0.7826086956521738| -1.1256647|\n",
      "|   424|    148|   4.0| 1.2173913043478262|  0.6146667|\n",
      "+------+-------+------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alsPredictionsDf = alsModel.transform(ratingsDf2)\n",
    "alsPredictionsDf.select(\"userID\", \"movieID\", \"rating\", \"adjustedRating\", \"prediction\") \\\n",
    "                .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, rating: double, timestamp: timestamp, userID: bigint, avg(rating): double, adjustedRating: double, prediction: float]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alsPredictionsDf.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate using the root mean squared error (RMSE).\n",
    "rmse = RegressionEvaluator(labelCol=\"adjustedRating\",\n",
    "                           predictionCol=\"prediction\",\n",
    "                           metricName=\"rmse\").evaluate(alsPredictionsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate using the coefficient of determination (R^2 score).\n",
    "r2 = RegressionEvaluator(labelCol=\"adjustedRating\",\n",
    "                         predictionCol=\"prediction\",\n",
    "                         metricName=\"r2\").evaluate(alsPredictionsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) = 0.763837\n",
      "Coefficient of Determination (R^2) = 0.385886\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) = %g\" % rmse)\n",
    "print(\"Coefficient of Determination (R^2) = %g\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The reason I trained and tested the model on the same dataset (instead of randomly splitting it into two disjoint datasets, one for training and the other for test) is [this](https://issues.apache.org/jira/browse/SPARK-14489). Apparently the problem was fixed in Spark 2.2.0 with the addition of a new input parameter for ALS, but I'm currently using Spark 2.1.0 (latest stable version when I wrote this), so it is not available yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
